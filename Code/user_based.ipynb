{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from math import sqrt\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapDict(vals):\n",
    "        return_dict = {}\n",
    "        for val in vals:\n",
    "            return_dict[val[0]] = val[1]\n",
    "        return return_dict\n",
    "\n",
    "def findAvg(vals):\n",
    "        '''Find average value for each row'''\n",
    "        count = 0\n",
    "        tot = 0\n",
    "        for item, rating in vals.items():\n",
    "            tot += rating\n",
    "            count += 1\n",
    "        average = float(tot) / count\n",
    "        \n",
    "        for item, rating in vals.items():\n",
    "            vals[item] = rating - average\n",
    "        vals['row_avg'] = average\n",
    "        return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sc.textFile('./Train-New.csv')\n",
    "test = sc.textFile('./Test-New.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_header = train.first()\n",
    "train_filtered = train.filter(lambda row: row != train_header)\n",
    "test_header = test.first()\n",
    "test_filtered = test.filter(lambda row: row != test_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = train_filtered.map(lambda x: x.split(',')).map(lambda line_split: (line_split[0], (line_split[1], float(line_split[2]))))\n",
    "test_rdd = test_filtered.map(lambda x: x.split(',')).map(lambda line_split: (line_split[0], line_split[1], float(line_split[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_group = train_rdd.groupByKey()\n",
    "training_group = train_rdd.groupByKey().mapValues(list)\n",
    "training_group_dict = training_group.mapValues(mapDict)\n",
    "training_group_dict_avg = training_group_dict.mapValues(findAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_group_dict_one = training_group_dict_avg.map(lambda x: (1, x))\n",
    "training_one_reduce = training_group_dict_one.groupByKey().mapValues(list).map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_compile = training_one_reduce.collect()\n",
    "training_data_compile = training_data_compile[0]\n",
    "training_compile_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_data_compile)):\n",
    "        training_compile_dict[training_data_compile[i][0]] = training_data_compile[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_user_pre = train_rdd.map(lambda x: (x[1][0], x[0])).groupByKey().mapValues(list)\n",
    "item_to_user_compile = item_to_user_pre.collect()\n",
    "item_to_user_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(item_to_user_compile)):\n",
    "        item_to_user_dict[item_to_user_compile[i][0]] = set(item_to_user_compile[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_rdd.collect()\n",
    "RMSE_tmp = 0\n",
    "tmp_result = []\n",
    "pearson_threshold = 0.3\n",
    "random_pred = 0\n",
    "upper_limit = 150\n",
    "lower_limit = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in test_data:\n",
    "        '''Get all the rows corresponding to cur user and item of test dataset'''\n",
    "        cur_item, cur_user = test[0], test[1]\n",
    "        filtered_train = {}\n",
    "        if cur_item not in training_compile_dict or cur_user not in item_to_user_dict:\n",
    "            '''If it's an unseen business id, assign some random prediction'''\n",
    "            prediction = 5\n",
    "            random_pred += 1\n",
    "        else:\n",
    "            '''We want to attach row corresponding to current item'''\n",
    "            filtered_train[cur_item] = training_compile_dict[cur_item]\n",
    "            cur_item_info = filtered_train[cur_item]\n",
    "            '''Get a list of user_id who contains the current item'''\n",
    "            row_set = item_to_user_dict[cur_user]\n",
    "            for row in row_set:\n",
    "                if len(training_compile_dict[row]) > lower_limit and len(training_compile_dict[row]) < upper_limit:\n",
    "                    filtered_train[row] = training_compile_dict[row]\n",
    "                \n",
    "            '''Compute Pearson for each row and add to the final result if Pearson\n",
    "            passes the threshold value'''\n",
    "            predict_num = 0\n",
    "            predict_den = 0\n",
    "            for item, user_list in filtered_train.items():\n",
    "                if item != cur_item:\n",
    "                    num = 0\n",
    "                    den1 = 0\n",
    "                    den2 = 0\n",
    "                    for user, rating in user_list.items():\n",
    "                        if user in cur_item_info and user != cur_user and user != 'row_avg':\n",
    "                            num += rating * cur_item_info[user]\n",
    "                            den1 += rating**2\n",
    "                            den2 += (cur_item_info[user])**2\n",
    "                    denom = sqrt(den1) * sqrt(den2)\n",
    "                    if num == 0 or denom == 0:\n",
    "                        pearson = 0\n",
    "                    else:\n",
    "                        pearson = float(num) / denom\n",
    "                    if pearson > pearson_threshold:\n",
    "                        predict_num += (filtered_train[item][cur_user] + filtered_train[item]['row_avg']) * pearson\n",
    "                        predict_den += abs(pearson)\n",
    "            if predict_num == 0 or predict_den == 0:\n",
    "                prediction = cur_item_info['row_avg']\n",
    "            else:\n",
    "                prediction = float(predict_num) / predict_den\n",
    "                prediction = (prediction + cur_item_info['row_avg']) / 2.0 \n",
    "        '''Save the results which consists of user_id, business_id, ground truth and predicted'''\n",
    "        tmp_result.append(((test[1], test[0], test[2]), prediction))\n",
    "        '''Compile results for final MSE computation'''\n",
    "        RMSE_tmp += (test[2] - prediction)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = sqrt(RMSE_tmp / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.3020836340409767\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
